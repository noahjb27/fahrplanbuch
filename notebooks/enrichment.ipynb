{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Enrichment and Neo4j Loading\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEnricher:\n",
    "    def __init__(self, year: int, side: str):\n",
    "        self.year = year\n",
    "        self.side = side\n",
    "        self.data_dir = Path('../data')\n",
    "        \n",
    "    def load_and_combine_data(self):\n",
    "        \"\"\"Load and combine matched and refined data.\"\"\"\n",
    "        # Load matched stations\n",
    "        matched_path = self.data_dir / 'interim' / 'stops_matched' / f'stops_{self.year}_{self.side}.csv'\n",
    "        matched_stops = pd.read_csv(matched_path)\n",
    "        \n",
    "        # Load refined stations\n",
    "        refined_path = self.data_dir / 'interim' / 'stops_refined' / f'stops_{self.year}_{self.side}_refined.csv'\n",
    "        refined_stops = pd.read_csv(refined_path)\n",
    "        \n",
    "        # Combine data\n",
    "        final_stops = matched_stops.copy()\n",
    "        mask = final_stops['location'].isna()\n",
    "        final_stops.loc[mask] = refined_stops[mask]\n",
    "        \n",
    "        self.stops_df = final_stops\n",
    "        logger.info(f\"Loaded {len(self.stops_df)} total stations\")\n",
    "        \n",
    "    def add_administrative_data(self):\n",
    "        \"\"\"Add administrative boundary information.\"\"\"\n",
    "        # Load GeoJSON data\n",
    "        districts_gdf = gpd.read_file(\"../data-external/lor_ortsteile.geojson\")\n",
    "        \n",
    "        # Convert stations to GeoDataFrame\n",
    "        geometry = self.stops_df['location'].apply(lambda x: \n",
    "            Point(*map(float, x.split(','))))\n",
    "        stops_gdf = gpd.GeoDataFrame(self.stops_df, geometry=geometry)\n",
    "        \n",
    "        # Perform spatial join\n",
    "        stops_with_admin = gpd.sjoin(\n",
    "            stops_gdf, \n",
    "            districts_gdf[['geometry', 'BEZIRK', 'OTEIL']], \n",
    "            how=\"left\", \n",
    "            predicate='within'\n",
    "        )\n",
    "        \n",
    "        self.stops_df = stops_with_admin\n",
    "        logger.info(\"Added administrative data\")\n",
    "        \n",
    "    def add_east_west_classification(self):\n",
    "        \"\"\"Add East/West classification based on location.\"\"\"\n",
    "        # Load West Berlin districts\n",
    "        with open(\"../data-external/West-Berlin-Ortsteile.json\", \"r\") as f:\n",
    "            west_berlin = json.load(f)[\"West_Berlin\"]\n",
    "            \n",
    "        # Classify stations\n",
    "        self.stops_df['east_west'] = self.stops_df['OTEIL'].apply(\n",
    "            lambda x: 'west' if x in west_berlin else 'east'\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Added East/West classification\")\n",
    "        \n",
    "    def enrich_transport_data(self):\n",
    "        \"\"\"Add transport-specific enrichment.\"\"\"\n",
    "        # Calculate transfer points\n",
    "        transfer_points = self.stops_df.groupby('stop_name').agg({\n",
    "            'type': 'nunique',\n",
    "            'in_lines': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Add transfer point flag\n",
    "        self.stops_df = self.stops_df.merge(\n",
    "            transfer_points,\n",
    "            on='stop_name',\n",
    "            suffixes=('', '_count')\n",
    "        )\n",
    "        \n",
    "        self.stops_df['is_transfer'] = (\n",
    "            self.stops_df['type_count'] > 1) | (self.stops_df['in_lines_count'] > 1\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Added transport enrichment\")\n",
    "        \n",
    "    def prepare_for_neo4j(self):\n",
    "        \"\"\"Prepare data for Neo4j import.\"\"\"\n",
    "        # Add required fields\n",
    "        self.stops_df['created_at'] = pd.Timestamp.now()\n",
    "        self.stops_df['source'] = f'fahrplanbuch_{self.year}'\n",
    "        \n",
    "        # Clean and validate data\n",
    "        self.stops_df = self.stops_df.fillna('')\n",
    "        \n",
    "        return self.stops_df\n",
    "\n",
    "# Example usage:\n",
    "year = 1965\n",
    "side = 'west'\n",
    "\n",
    "enricher = DataEnricher(year, side)\n",
    "enricher.load_and_combine_data()\n",
    "enricher.add_administrative_data()\n",
    "enricher.add_east_west_classification()\n",
    "enricher.enrich_transport_data()\n",
    "final_df = enricher.prepare_for_neo4j()\n",
    "\n",
    "# Save enriched data\n",
    "output_path = f'../data/processed/stops_{year}_{side}_final.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "logger.info(f\"Saved enriched data to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
